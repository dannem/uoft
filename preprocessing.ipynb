{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import random\n",
    "import sys\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from auxiliary_analysis import *\n",
    "from scipy.spatial.distance import squareform\n",
    "mne.__version__\n",
    "mne.set_log_level(\"WARNING\")\n",
    "\n",
    "infolder, outfolder = find_folder()\n",
    "conf = dict()\n",
    "\n",
    "# EEG parameters\n",
    "resample = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imagery Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining triggers\n",
    "trigs=list(range(31, 36))\n",
    "event_ids={str(x):x for x in trigs}\n",
    "all_accuracies = pd.DataFrame() # DF to store SVM results\n",
    "\n",
    "# Preprocessing Params\n",
    "start = 2 # first participant\n",
    "end = 3 # last participant\n",
    "random_participants = False\n",
    "n_participants = 5\n",
    "verbose = False\n",
    "\n",
    "# If you want to pick a sample of random participants, change random_participants to True\n",
    "# and n_participants to the sample size\n",
    "if random_participants:\n",
    "   participants = np.random.randint(start, end, n_participants)\n",
    "else:\n",
    "  participants = range(start, end)\n",
    "\n",
    "participants = [2,3,4,6,12,18]\n",
    "\n",
    "for i in participants:\n",
    "  count = 0\n",
    "\n",
    "  # Generate bdf file names\n",
    "  id = str(i).zfill(2)\n",
    "  file_name_1 = 'IR_' + id + '_S01.bdf'\n",
    "  file_name_2 = 'IR_' + id + '_S02.bdf'\n",
    "  file_name_3= 'IR_' + id + '_S03.bdf'\n",
    "\n",
    "  # Loading participant's first session\n",
    "  fname = op.join(infolder,file_name_1)\n",
    "\n",
    "  # Convert to epochs\n",
    "  epochs_a = preprocessing_eeg(fname, event_ids, segment_times=(-1,5), resample = resample)\n",
    "\n",
    "  # Loading participant's second session\n",
    "  fname = op.join(infolder,file_name_2)\n",
    "\n",
    "  # Convert to epochs\n",
    "  epochs_b = preprocessing_eeg(fname, event_ids, segment_times=(-1,5), resample = resample)\n",
    "\n",
    "  # If second participant, add another session because P2 has 3 sessions\n",
    "  if (i == 2):\n",
    "     epochs_c = preprocessing_eeg(fname, event_ids, segment_times=(-1,5), resample = resample)\n",
    "     epochs_im = mne.concatenate_epochs([epochs_a,epochs_b, epochs_c])\n",
    "  else:\n",
    "    fname = op.join(infolder,file_name_3)\n",
    "    epochs_im = mne.concatenate_epochs([epochs_a,epochs_b])\n",
    "\n",
    "  %reset_selective -f 4_\n",
    "\n",
    "  # Dropping status channel\n",
    "  epochs_im.drop_channels('Status')\n",
    "\n",
    "  # Equalizing number of cases between conditions\n",
    "  epochs_im.equalize_event_counts(event_ids=event_ids, method='mintime') \n",
    "\n",
    "  # z-scoring, thresholding, rereferencing\n",
    "  epochs_im = zscore_threshold_epochs(epochs_im, 2, 3, time = True) \n",
    "\n",
    "  epochs_im.set_eeg_reference(\"average\")\n",
    "\n",
    "  # save as fif\n",
    "  fname = op.join(outfolder,'S' + id + '_imag-epo.fif')\n",
    "  epochs_im.save(fname, overwrite = True)\n",
    "\n",
    "  # averaging by block\n",
    "  epochs_im = block_average(epochs_im, 8)\n",
    "\n",
    "  # save as fif again\n",
    "  fname = op.join(outfolder,'S' + id + '_imag_aver-epo.fif')\n",
    "  epochs_im.save(fname, overwrite = True)\n",
    "\n",
    "  print(f'Session {i} preprocessed') if verbose else None\n",
    "\n",
    "  # SVM setup\n",
    "  im_names = ['mcy','sgo','sjo','est','tsw']\n",
    "  times=[(-1, 0),(0,5),(0,4),(0,3),(0,2),(0,1),(1,2),(1,3),(1,4),(1,5),(2,3),(2,4),(2,5),(3,4),(3,5),(4,5)]\n",
    "  results=[]\n",
    "  durs=[];\n",
    "\n",
    "  # Running SVM\n",
    "  for j in times:\n",
    "    X, Y = convert_epochs_to_2D_array(epochs_im, times=j)\n",
    "    confusion, duration = run_eeg_svm(X,Y,6)\n",
    "    results.append(confusion)\n",
    "    durs.append(duration)\n",
    "\n",
    "  print(f'Session {i} analysed:') if verbose else None\n",
    "\n",
    "  accuracies = []\n",
    "\n",
    "  for k in results:\n",
    "      print(f'Accuracy of the entire set is {np.mean(squareform(k))*100:.2f}%') if verbose else None\n",
    "      accuracies.append(round(np.mean(squareform(k))*100, 2))\n",
    "  all_accuracies.insert(count, f'Participant {i}', accuracies, True)\n",
    "  confusion_df = pd.DataFrame(results[3], columns = im_names, index = im_names)\n",
    "  fname = op.join(outfolder,'conf_IR_' + str(i).zfill(2) + '_imag.csv')\n",
    "  confusion_df.to_csv(fname, index = True, header = True)\n",
    "  count+=1\n",
    "\n",
    "all_accuracies.to_csv(\"image_accuracies2.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perception Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining triggers\n",
    "trigs=list(range(101, 151))+list(range(201, 251))\n",
    "event_ids={str(x):x for x in trigs}\n",
    "\n",
    "start = 3\n",
    "end = 4\n",
    "\n",
    "# Generate an array of 4 random integers in the specified range\n",
    "\n",
    "for i in range(start, end):\n",
    "  file_name_1 = 'IR_' + str(i).zfill(2) + '_S01.bdf'\n",
    "  file_name_2 = 'IR_' + str(i).zfill(2) + '_S02.bdf'\n",
    "\n",
    "  # Loading first session\n",
    "  fname = op.join(infolder,file_name_1)\n",
    "\n",
    "  # Load data\n",
    "  epochs_a = preprocessing_eeg(fname, event_ids, segment_times=(-0.1,1), resample = resample)\n",
    "  epochs_a = epochs_a[100:]\n",
    "\n",
    "  # Loading second session\n",
    "  file_name=file_name_2\n",
    "  fname = op.join(infolder,file_name_2)\n",
    "\n",
    "  # Load data\n",
    "  epochs_b = preprocessing_eeg(fname, event_ids, segment_times=(-0.1,1), resample = resample)\n",
    "  epochs_b = epochs_b[100:]\n",
    "\n",
    "  # creating one data\n",
    "  epochs_perc = mne.concatenate_epochs([epochs_a,epochs_b])\n",
    "  %reset_selective -f 4_\n",
    "\n",
    "  #dropping status channel\n",
    "  epochs_perc.drop_channels('Status')\n",
    "\n",
    "  # equalizing number of cases between conditions\n",
    "  epochs_perc.equalize_event_counts(event_ids=event_ids, method='mintime') \n",
    "\n",
    "  # adding metadata\n",
    "  epochs_perc.metadata = create_meta_events_perception(epochs_perc.events[:,2]) \n",
    "\n",
    "\n",
    "  # zscoring, thresholding, rereferencing\n",
    "  epochs_perc = zscore_threshold_epochs(epochs_perc, dims=2, threshold=3) \n",
    "  epochs_perc.set_eeg_reference(\"average\")\n",
    "  \n",
    "  # saving\n",
    "  fname = op.join(outfolder,'S' + str(i).zfill(2) + '_perc-epo.fif')\n",
    "  epochs_perc.save(fname, overwrite = True)\n",
    "\n",
    "  # averaging by block\n",
    "  epochs_perc = block_average(epochs_perc, 4)\n",
    "\n",
    "  # saving\n",
    "  fname = op.join(outfolder,'S' + str(i).zfill(2) + '_perc_aver-epo.fif')\n",
    "  epochs_perc.save(fname, overwrite = True)\n",
    "\n",
    "  os.system(f'say \"Participant {i} preprocessed\"')\n",
    "\n",
    "  times=[(0.05,0.65)]\n",
    "  results=[]\n",
    "  durs=[]\n",
    "\n",
    "  for j in times:\n",
    "    X, Y = convert_epochs_to_2D_array(epochs_perc, times=j)\n",
    "    confusion, duration = run_eeg_svm(X, Y, 12)\n",
    "    results.append(confusion)\n",
    "    durs.append(duration)\n",
    "\n",
    "  # os.system(f'say \"Session {i} analysed\"')\n",
    "\n",
    "  confusion=results[0]\n",
    "  print(f'Session {i} analysed with dimensions {d}:')\n",
    "  print(f'Accuracy of the upright stimuli is {np.mean(squareform(confusion[0:50,0:50]))*100:.4f}%')\n",
    "  print(f'Accuracy of the upright unfamiliary stimuli is {np.mean(squareform(confusion[0:25,0:25]))*100:.4f}%')\n",
    "  print(f'Accuracy of the upright famous stimuli is {np.mean(squareform(confusion[25:50,25:50]))*100:.4f}%')\n",
    "  print(f'Accuracy of the inverted stimuli is {np.mean(squareform(confusion[50:,50:]))*100:.4f}%')\n",
    "  print(f'Accuracy of the inverted unfamiliar stimuli is {np.mean(squareform(confusion[50:75,50:75]))*100:.4f}%')\n",
    "  print(f'Accuracy of the inverted famous stimuli is {np.mean(squareform(confusion[75:,75:]))*100:.4f}%')\n",
    "  print(f'Accuracy of the entire set is {np.mean(squareform(confusion))*100:.4f}%')\n",
    "\n",
    "  ## Correlation results\n",
    "  corr=np.corrcoef(squareform(confusion[0:25,0:25]),squareform(confusion[50:75,50:75]))\n",
    "  print(f'Correlation between identity discrimination in upright and inverted famous faces is {corr[0,1]:.3f}')\n",
    "  corr=np.corrcoef(squareform(confusion[25:50,25:50]),squareform(confusion[75:100,75:100]))\n",
    "  print(f'Correlation between identity discrimination in upright and inverted unfamiliar faces is {corr[0,1]:.3f}')\n",
    "  conf['perc'] = results[0]\n",
    "  file_name='conf_mat_perc_' + str(i).zfill(2) + '.csv'\n",
    "  fname = op.join(outfolder,file_name)\n",
    "  np.savetxt(fname, conf['perc'], delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
